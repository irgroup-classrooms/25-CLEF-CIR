{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abbffddf-5c12-4011-b1e9-4e4f17c6abcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "DATABASE = \"longeval-web\"\n",
    "USER = \"dis18\"\n",
    "HOST = \"db\"\n",
    "PORT = \"5432\"\n",
    "PASSWORD = \"dis182425\"\n",
    "\n",
    "engine = create_engine(f\"postgresql+psycopg2://{USER}:{PASSWORD}@{HOST}:{PORT}/{DATABASE}\")\n",
    "\n",
    "df = pd.read_sql('select * from \"Topic\" limit 1', con=engine)\n",
    "sql_query = lambda x: pd.read_sql(x, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6382e569-cc0e-433b-a085-77b12587766f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_connection():\n",
    "    \"\"\"\n",
    "    Creates an engine the process can use for multi processing.\n",
    "    Remark: Connection gets lost if each worker connects via the same connection.\n",
    "    \"\"\"\n",
    "    DATABASE = \"longeval-web\"\n",
    "    USER = \"dis18\"\n",
    "    HOST = \"db\"\n",
    "    PORT = \"5432\"\n",
    "    PASSWORD = \"dis182425\"\n",
    "    \n",
    "    engine = create_engine(f\"postgresql+psycopg2://{USER}:{PASSWORD}@{HOST}:{PORT}/{DATABASE}\")\n",
    "    \n",
    "    return lambda x: pd.read_sql(x, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba4dbbe5-9330-4594-b4af-44ef505e9712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: ClaudeAI (ran into max connection problem)\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.pool import QueuePool\n",
    "def create_engine_with_pool():\n",
    "    \"\"\"\n",
    "    Creates an engine with proper connection pooling configuration.\n",
    "    \"\"\"\n",
    "    DATABASE = \"longeval-web\"\n",
    "    USER = \"dis18\"\n",
    "    HOST = \"db\"\n",
    "    PORT = \"5432\"\n",
    "    PASSWORD = \"dis182425\"\n",
    "    \n",
    "    return create_engine(\n",
    "        f\"postgresql+psycopg2://{USER}:{PASSWORD}@{HOST}:{PORT}/{DATABASE}\",\n",
    "        poolclass=QueuePool,\n",
    "        pool_size=5,  # Number of permanent connections\n",
    "        max_overflow=10,  # Number of additional connections that can be created\n",
    "        pool_timeout=30,  # Timeout waiting for a connection (seconds)\n",
    "        pool_recycle=1800,  # Recycle connections after 30 minutes\n",
    "        pool_pre_ping=True  # Verify connection validity before using\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b9307ad-8f24-4a67-a390-3e20ae9377ef",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sub_collection    count\n",
      "0        2022-06  1775681\n",
      "1        2022-07  1777616\n",
      "2        2022-08  1787018\n",
      "3        2022-09  1210186\n",
      "4        2022-10  2418103\n",
      "5        2022-11  2433787\n",
      "6        2022-12  2534242\n",
      "7        2023-01  2537565\n",
      "8        2023-02  2526382\n"
     ]
    }
   ],
   "source": [
    "# Get sub_collection and count(*) for each\n",
    "query= \"\"\"\n",
    "select sub_collection, count(*)\n",
    "from \"Document\"\n",
    "group by sub_collection\n",
    "\"\"\"\n",
    "df_subcol_count = sql_query(query)\n",
    "print(df_subcol_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "719a686c-b3d5-4d0b-bcd4-a783f89479a9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06 1775681 \n",
      "\n",
      "2022-07 1777616 \n",
      "\n",
      "2022-08 1787018 \n",
      "\n",
      "2022-09 1210186 \n",
      "\n",
      "2022-10 2418103 \n",
      "\n",
      "2022-11 2433787 \n",
      "\n",
      "2022-12 2534242 \n",
      "\n",
      "2023-01 2537565 \n",
      "\n",
      "2023-02 2526382 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    None\n",
       "1    None\n",
       "2    None\n",
       "3    None\n",
       "4    None\n",
       "5    None\n",
       "6    None\n",
       "7    None\n",
       "8    None\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_col_name: str= None\n",
    "sub_count: int = None \n",
    "sub_batch_size = 1000\n",
    "\n",
    "df_subcol_count.apply(lambda x:print(x[\"sub_collection\"],x[\"count\"],\"\\n\"), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad2b64e-8d67-4183-a71d-1f8f1e716252",
   "metadata": {},
   "source": [
    "# 2.Pipeline Term Frequency on Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af5525c-68d2-466e-9067-adf186258021",
   "metadata": {},
   "source": [
    "## 2.1 Inner Parallel Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fe9af26-9720-4082-ade8-a29a4ce1fad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from unidecode import unidecode\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "nltk.download('stopwords')\n",
    "french_stopwords = set(stopwords.words('french'))\n",
    "    \n",
    "# Add additional French stopwords (articles, prepositions, etc.)\n",
    "additional_stopwords = {\n",
    "    'a', 'au', 'aux', 'avec', 'ce', 'ces', 'dans', 'de', 'des', 'du', 'en',\n",
    "    'et', 'il', 'ils', 'je', 'j', 'la', 'le', 'les', 'leur', 'lui', 'ma',\n",
    "    'mais', 'me', 'même', 'mes', 'moi', 'mon', 'ni', 'notre', 'nous', 'on',\n",
    "    'ou', 'par', 'pas', 'pour', 'qu', 'que', 'qui', 'sa', 'se', 'si', 'son',\n",
    "    'sur', 'ta', 'te', 'tes', 'toi', 'ton', 'tu', 'un', 'une', 'vos', 'votre',\n",
    "    'vous',\n",
    "    'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z',\n",
    "    # Numbers written as words\n",
    "    'zero', 'un', 'deux', 'trois', 'quatre', 'cinq', 'six', 'sept', 'huit', 'neuf', 'dix',\n",
    "        '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10'\n",
    "}\n",
    "\n",
    "# Combine standard and additional stopwords\n",
    "stop_words = french_stopwords.union(additional_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41bea33-1597-4939-8843-edc24f62580f",
   "metadata": {},
   "source": [
    "# 3. MultiHotEncoding Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caf33b4-fd87-4e6e-ae53-697c34a699c5",
   "metadata": {},
   "source": [
    "## 3.1 Inner Parallel Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e350b1d-de68-4753-a636-0d93409101d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_text (text, top_words_list):\n",
    "    \"\"\"\n",
    "    Stems text and returns only terms included in top_words_list.\n",
    "    \"\"\"\n",
    "    fr_sbst = SnowballStemmer(\"french\")\n",
    "    french_stopwords = set(stopwords.words('french'))\n",
    "    \n",
    "    # Add additional French stopwords (articles, prepositions, etc.)\n",
    "    additional_stopwords = {\n",
    "        'a', 'au', 'aux', 'avec', 'ce', 'ces', 'dans', 'de', 'des', 'du', 'en',\n",
    "        'et', 'il', 'ils', 'je', 'j', 'la', 'le', 'les', 'leur', 'lui', 'ma',\n",
    "        'mais', 'me', 'même', 'mes', 'moi', 'mon', 'ni', 'notre', 'nous', 'on',\n",
    "        'ou', 'par', 'pas', 'pour', 'qu', 'que', 'qui', 'sa', 'se', 'si', 'son',\n",
    "        'sur', 'ta', 'te', 'tes', 'toi', 'ton', 'tu', 'un', 'une', 'vos', 'votre',\n",
    "        'vous',\n",
    "        'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z',\n",
    "        # Numbers written as words\n",
    "        'zero', 'un', 'deux', 'trois', 'quatre', 'cinq', 'six', 'sept', 'huit', 'neuf', 'dix',\n",
    "        '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10'\n",
    "    }\n",
    "    \n",
    "    # Combine standard and additional stopwords\n",
    "    stop_words = french_stopwords.union(additional_stopwords)\n",
    "    # Start\n",
    "    text = re.sub(r'[^\\w\\s]|[\\d]', '', text)\n",
    "    words_document = [unidecode(word.lower()) for word in list(text.split())]\n",
    "    words_document_stem = [fr_sbst.stem(word) for word in words_document if not word.lower() in stop_words]\n",
    "    return [word for word in words_document_stem if word in top_words_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "066658dc-415d-4477-85aa-197f3d20fa7e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def  create_words_index(df_terms_stem, n_words):\n",
    "    \"\"\"\n",
    "    Creates translation table for term <> index.\n",
    "    \"\"\"\n",
    "    df_words_index = df_terms_stem.iloc[:n_words, :1].copy().reset_index()\n",
    "    df_words_index[\"index\"] = df_words_index.index.tolist()\n",
    "    df_words_index.to_csv(\"words_index_translationtable.csv\", index=False)\n",
    "    return df_words_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03d9fc18-2b95-4220-ab1f-42d94937346b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_term_index(word_list, term_idx_table):\n",
    "    \"\"\"\n",
    "    Searches for the corresponding index for each term.\n",
    "    \"\"\"\n",
    "    df_index = pd.DataFrame(word_list, columns=[\"term\"])\n",
    "    df_index = df_index.merge(term_idx_table, how=\"left\", left_on=\"term\", right_on=\"term\")\n",
    "    return  df_index[\"index\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c9c8275-4b0c-4bb3-9fda-28ab3faac115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topiccluster(docs_topwords):\n",
    "    \"\"\"\n",
    "    Enriches Data Frame with corresponding Topic Cluster.\n",
    "    \"\"\"\n",
    "    topic_cluster = pd.read_csv(\"topics_embedding_category_clustering.csv\")\n",
    "    #print(topic_cluster.columns.tolist())\n",
    "    #print(topic_cluster.head())\n",
    "    # Merge Cluster to Document Data Frame\n",
    "    docs_topwords = docs_topwords.merge(topic_cluster[[\"queryid\", \"cluster\"]], how=\"left\", left_on=\"queryid\", right_on=\"queryid\")\n",
    "    \n",
    "    return docs_topwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95aa925d-f916-4cb9-a44f-2655bbd48c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def documents_topwords_filter(df_batch, top_words_list):\n",
    "    \"\"\"\n",
    "    Splits text of each document and stems the content.\n",
    "    Filters stemmed terms, to only include top_words_list entries.\n",
    "    Returns DataFrame with Filtered terms for each document.\n",
    "    \"\"\"\n",
    "    #df_batch_filtered = pd.DataFrame(columns=[\"docid\",\"term_list_stemmed\"])\n",
    "    #df_batch_filtered[\"docid\"] = df_batch[\"docid\"].copy()\n",
    "    #df_batch_filtered[\"term_list_stemmed\"] = df_batch[\"text_fr\"].apply(lambda x: stem_text(x, top_words_list))\n",
    "    df_batch[\"term_list_stemmed\"] = df_batch[\"text_fr\"].apply(lambda x: stem_text(x, top_words_list))\n",
    "    \n",
    "    return df_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6bcf504-6393-4421-8292-2bd590ae8b46",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_batch_MHE(batch_id: int, batch, top_words_list, df_words_index):\n",
    "    \"\"\"\n",
    "    Processes Single Batch from Parallel Batch Processing.\n",
    "    \"\"\"\n",
    "    batch_list = \"\".join(f\"'{batch[i]}',\" if i+1 <  len(batch) else f\"'{batch[i]}'\" for i in range(len(batch)))\n",
    "    #print(n_begin, n_end)\n",
    "    q_batch = f\"\"\"\n",
    "    select distinct docid, text_fr, sub_collection\n",
    "    from \"Document\" a\n",
    "    where     a.sub_collection = '2023-02'\n",
    "          and a.docid in ({batch_list})\n",
    "    order by  a.docid\n",
    "    \"\"\"\n",
    "    engine = create_engine_with_pool()\n",
    "    try:\n",
    "        df_batch = pd.read_sql(q_batch, con=engine)\n",
    "        df_batch = documents_topwords_filter(df_batch, top_words_list)\n",
    "        df_batch[\"term_idx\"] = df_batch[\"term_list_stemmed\"].apply(lambda x: get_term_index(word_list=x,term_idx_table=df_words_index))\n",
    "        df_batch = df_batch.loc[:,[\"docid\", \"sub_collection\", \"term_idx\"]]\n",
    "        return batch_id, df_batch\n",
    "    finally:\n",
    "        engine.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455420c9-4ea4-4b58-b5d4-4f8e73bc5e21",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 3.2 Outer Parallel Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23b07c5c-ac46-4845-aa0a-d2e789d40791",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parallel Processing\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import time\n",
    "from typing import List\n",
    "\n",
    "def parallel_MultiHotEncoding(docids: list, n_docs, top_words_list, df_words_index):\n",
    "    \"\"\"\n",
    "    Starts Parallel Processing.\n",
    "    \"\"\"\n",
    "    docs_list = docids\n",
    "    func_slice_batch = lambda begin, end: docs_list[begin:end]\n",
    "    \n",
    "    workers = 16  # max sind 32 ich nehm 12 # habe max worker für sql erreicht 12 sind zu viel\n",
    "    batch_size = 1000\n",
    "\n",
    "    n_docs = n_docs if n_docs == len(docs_list) else len(docs_list)\n",
    "    batches = []\n",
    "    for i in range(0, n_docs, batch_size):\n",
    "        end_idx = min(i + batch_size, n_docs) # last batch is smaller due to hitting n_docs as maximum\n",
    "        batches.append((i, func_slice_batch(i, end_idx)))\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=workers) as executor:\n",
    "        # Submit all batches and store futures\n",
    "        future_to_batch = {\n",
    "        executor.submit(process_batch_MHE, batch_id, batch, top_words_list, df_words_index): batch_id for batch_id, batch in batches\n",
    "        }\n",
    "\n",
    "        results = {}\n",
    "\n",
    "        with tqdm(as_completed(future_to_batch), total=len(future_to_batch), desc=\"Batch Progress\") as pbar:\n",
    "            for i, future in enumerate(pbar):\n",
    "                batch_id, result = future.result()\n",
    "                results[batch_id] = result\n",
    "                pbar.set_description(f\"Processing batch {i}\")\n",
    "\n",
    "    #print(\"Available batch keys:\", results.keys())\n",
    "    #print(\"Trying to access batches 0 to\", len(batches)-1)\n",
    "    #print(results)\n",
    "    first_batch = batches[0][0]\n",
    "    final_results = results[first_batch]\n",
    "    for i in batches[1:]:\n",
    "        final_results = pd.concat([final_results, results[i[0]]], ignore_index=True) # i is the batch tuple (batch_id, (func_inner, ... addittional parameters))\n",
    "        \n",
    "    print(f\"Processed {n_docs} items in {len(batches)} batches\")\n",
    "    print(f\"Time taken: {time.time() - start_time:.2f} seconds\")\n",
    "    print(f\"Filtered Text for {len(top_words_list)} Top Words of the Corpus.\")\n",
    "    print(f\"First few results: {final_results[:5]}\")\n",
    "\n",
    "    return final_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48fb25c8-eb7c-4195-8381-7ecfe085916b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def multi_hot_encoding(docids:list, n_docs:int, df_terms_stem, n_words):\n",
    "    \"\"\"\n",
    "    Starts transforming\n",
    "    \"\"\"\n",
    "    # Preparation for Parallel Processing\n",
    "    print(f\"Processing {n_docs} documents with Top {n_words} words\")\n",
    "    top_words_list = df_terms_stem.iloc[:n_words, 0].to_list()\n",
    "    df_words_index = create_words_index(df_terms_stem, n_words=n_words)\n",
    "    \n",
    "    # Iterative Processing via Parallel Processing\n",
    "    docs_topwords = parallel_MultiHotEncoding(docids, n_docs, top_words_list, df_words_index) \n",
    "\n",
    "    return docs_topwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf302f8c-5121-4a85-8af0-485e78376f0f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "engine.dispose()\n",
    "#print(n_docs//10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "808ce69a-6c32-4435-9cd4-1bc8ff73cde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read searchresults\n",
    "f_results = \"run_docids.csv\"\n",
    "df_search = pd.read_csv(f_results)\n",
    "q = f\"\"\"\n",
    "select a.*\n",
    "    from \"Document\" a\n",
    "    join (\n",
    "          select ('doc'|| b_inner.docid)new_docid , *\n",
    "          from \"Qrel\" b_inner\n",
    "          where queryid in (\n",
    "                select queryid\n",
    "                from \"Qrel\" \n",
    "                where sub_collection = '2023-02'\n",
    "          )\n",
    "    ) b\n",
    "    on        a.docid = b.new_docid\n",
    "          and a.sub_collection = b.sub_collection\n",
    "    join (\n",
    "          select *\n",
    "          from \"Topic\"\n",
    "    ) c\n",
    "    on b.queryid = c.queryid  \n",
    "    where     a.sub_collection = '2023-02'\n",
    "          and b.sub_collection = '2023-02'\n",
    "          and b.relevance is not null\n",
    "          and a.sub_collection is not null\n",
    "          and b.queryid is not null\n",
    "    order by  a.docid\n",
    "\"\"\"\n",
    "#df_search = sql_query(q)\n",
    "df_search = df_search.drop_duplicates(subset=\"docno\")\n",
    "search_docids = df_search[\"docno\"].tolist()\n",
    "n_docs = len(search_docids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93e2a605-ca18-4649-b417-6bfb58db416e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating predict set for Search Results\n",
      "Unique documents found: 149782\n",
      "Use Top Terms from prior SubCollection:\t\tall_subcollections\n",
      "Processing 149782 documents with Top 10000 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 149: 100%|██████████| 150/150 [09:34<00:00,  3.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 149782 items in 150 batches\n",
      "Time taken: 574.80 seconds\n",
      "Filtered Text for 10000 Top Words of the Corpus.\n",
      "First few results:         docid sub_collection  \\\n",
      "0  doc1048365        2023-02   \n",
      "1  doc1048821        2023-02   \n",
      "2    doc11264        2023-02   \n",
      "3   doc114280        2023-02   \n",
      "4  doc1192329        2023-02   \n",
      "\n",
      "                                            term_idx  \n",
      "0  [8546, 453, 644, 716, 62, 175, 1133, 3694, 152...  \n",
      "1  [8, 153, 1825, 1475, 2262, 153, 7056, 1475, 78...  \n",
      "2  [582, 153, 1042, 5818, 1533, 3099, 809, 129, 4...  \n",
      "3  [7494, 49, 5114, 7494, 48, 48, 982, 1285, 2585...  \n",
      "4  [1295, 8, 164, 5634, 1829, 160, 527, 1153, 129...  \n",
      "\n",
      "!!!DONE!!!\n"
     ]
    }
   ],
   "source": [
    "# Overview over Search Content\n",
    "print(f\"Creating predict set for Search Results\")\n",
    "print(f\"Unique documents found: {len(search_docids)}\")\n",
    "\n",
    "subcollection = \"\"\n",
    "subcol_terms_used = \"all_subcollections\"\n",
    "\n",
    "# Get Top Words for each subcollection\n",
    "print(f\"Use Top Terms from prior SubCollection:\\t\\t{subcol_terms_used}\")\n",
    "df_terms_stem = pd.read_csv(f\"top_terms_stemmed_{subcol_terms_used}.csv\")\n",
    "\n",
    "# Get seperate MultiHotEncoded and Docs DataFrame from subcollection     \n",
    "docs_topwords = multi_hot_encoding(search_docids, n_docs, df_terms_stem, n_words=10_000)     #number of docs in subset:  n_docs\n",
    "docs_topwords.to_csv(f\"pred_set_{subcollection}_documents_top_terms_from-{subcol_terms_used}.csv\", index=False)\n",
    "    \n",
    "print(\"\\n!!!DONE!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9b818a6-2c53-4ebb-ad54-06bbf0ff669e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#13.27min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b5bb4c0-de99-44a5-aaa2-c8ec4875ce83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149782, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_topwords.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
