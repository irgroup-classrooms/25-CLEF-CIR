{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ee9251b-cfb6-4c5e-a4a1-7a9445fd4285",
   "metadata": {},
   "source": [
    "# This part of the code extracts only the most relevant queries and their documents (Relevanz = 2) from the original qrel files and stores them in a separate file.\n",
    "\n",
    "- This part of the code should be run separately for each qrels file.\n",
    "- After that you should save all the files obtained with this function in the qrels_r2 folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "573daf4b-531f-4452-9d76-e01f9bac4228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract only very relevant documents (Relevanz = 2) from original qrels\n",
    "def save_only_relevance_2(input_file, output_file='qrels_r2_23-02.txt'):\n",
    "    # Open the input file in read mode and the output file in write mode\n",
    "    with open(input_file, 'r', encoding='utf-8') as infile, \\\n",
    "         open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        \n",
    "        # Iterate over each line in the input file\n",
    "        for line in infile:\n",
    "            try:\n",
    "                # Strip whitespace and split the line into parts (by default, splits by any whitespace)\n",
    "                parts = line.strip().split()\n",
    "                \n",
    "                # Attempt to get the last element, which should be the relevance label, and convert it to an integer\n",
    "                last_number = int(parts[-1])\n",
    "                \n",
    "                # If the relevance label is exactly 2, write this line to the output file\n",
    "                if last_number == 2:\n",
    "                    outfile.write(line)\n",
    "            \n",
    "            except ValueError:\n",
    "                # If the last element cannot be converted to an integer (e.g. it's malformed), skip this line\n",
    "                continue\n",
    "\n",
    "# Usage of the function:\n",
    "save_only_relevance_2('datasets/LongEval-Web/release_2025_p1/French/LongEval Train Collection/qrels/2023-02_fr/qrels_processed.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e23c8b6-5555-41f3-a8a6-2584ab3c83f3",
   "metadata": {},
   "source": [
    "# This part of the code starts and loads the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "545bec08-002c-4187-a4f2-24c5c70ea164",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Java started and loaded: pyterrier.java, pyterrier.terrier.java [version=5.11 (build: craig.macdonald 2025-01-13 21:29), helper_version=0.0.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07:07:34.666 [main] WARN org.terrier.structures.BaseCompressingMetaIndex -- Structure meta reading data file directly from disk (SLOW) - try index.meta.data-source=fileinmem in the index properties file. 4.4 GiB of memory would be required.\n",
      "Number of documents: 2046080\n",
      "Number of terms: 5355232\n",
      "Number of postings: 672184530\n",
      "Number of fields: 0\n",
      "Number of tokens: 1693990317\n",
      "Field names: []\n",
      "Positions:   false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start index\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import pyterrier as pt\n",
    "if not pt.java.started():\n",
    "    pt.java.init()\n",
    "\n",
    "# Path to Index\n",
    "index_path = os.path.abspath(\"datasets/LongEval-Web/index/longeval-web-fr-2022-12-pyterrier\")\n",
    "index = pt.IndexFactory.of(index_path)\n",
    "\n",
    "# We need to output the index information because for the idf calculation we need to know the number of documents (line 3 of the index information)\n",
    "print(index.getCollectionStatistics().toString())\n",
    "\n",
    "# Access to index components\n",
    "lex = index.getLexicon()\n",
    "di = index.getDirectIndex()\n",
    "doi = index.getDocumentIndex()\n",
    "inv = index.getInvertedIndex()\n",
    "meta = index.getMetaIndex()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6c5658-3ee7-462e-b00b-68fee1dc2fc4",
   "metadata": {},
   "source": [
    "# Part 1: Query & Qrels Preprocessing Pipeline\n",
    "\n",
    "- This script loads and preprocesses query and qrels data from the LongEval French collection.\n",
    "- It merges queries with relevant document information and prepares them for retrieval experiments.\n",
    "- The preprocessing includes cleaning query strings and mapping document IDs to internal index IDs using a metadata\n",
    "- The Part from 1 to 7 must be run separately for each time period․"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64e81905-7e5e-42df-a3d3-48c941ddafce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# Load queries from a custom .txt file into a DataFrame\n",
    "def load_queries():\n",
    "    queries_path = \"datasets/LongEval-Web/release_2025_p1/French/LongEval Train Collection/queries/2022-12_queries.txt\"\n",
    "    qs = []\n",
    "    with open(queries_path, \"r\") as f:\n",
    "        for l in f.readlines():\n",
    "            splits = l.split(\"\\t\")\n",
    "            qs.append({\"qid\": splits[0], \"query\": splits[1].strip(\"\\n\")})\n",
    "    return pd.DataFrame(qs)\n",
    "\n",
    "# Load filtered qrels (only relevance=2), drop the unused column\n",
    "qrels_path = \"qrels_r2/qrels_r2_22-12.txt\"\n",
    "qrels = pd.read_csv(qrels_path, sep=\" \", names=[\"qid\", \"unused\", \"docid\", \"relevance\"], dtype={\"qid\": str})\n",
    "qrels = qrels.drop(columns=[\"unused\"])\n",
    "\n",
    "# Load queries\n",
    "queries = load_queries()\n",
    "\n",
    "# Merge qrels with corresponding queries by qid\n",
    "merged_qrels = pd.merge(qrels, queries, on=\"qid\", how=\"left\")\n",
    "\n",
    "# Clean queries: remove punctuation and special characters\n",
    "def clean_query(query):\n",
    "    return re.sub(r\"[^\\w\\s]\", \"\", str(query))  # Removes special characters\n",
    "\n",
    "merged_qrels[\"query\"] = merged_qrels[\"query\"].apply(clean_query)\n",
    "\n",
    "# Add document ID prefix expected by the index\n",
    "merged_qrels[\"docid_qrels\"] = \"doc\" + merged_qrels[\"docid\"].astype(str)\n",
    "\n",
    "# Map document IDs to internal index IDs using a metadata object (assumed global)\n",
    "def get_docid_index(docno):\n",
    "    try:\n",
    "        return meta.getDocument(\"docno\", docno)\n",
    "    except Exception:\n",
    "        return None  # If lookup fails\n",
    "\n",
    "merged_qrels[\"docid_index\"] = merged_qrels[\"docid_qrels\"].apply(get_docid_index)\n",
    "\n",
    "# Reorganize columns for clarity\n",
    "final_qrels = merged_qrels[[\"qid\", \"docid_qrels\", \"docid_index\", \"relevance\", \"query\"]]\n",
    "\n",
    "# Clean: remove rows with missing queries or document index lookup failures\n",
    "final_qrels = final_qrels.copy()\n",
    "final_qrels['query'] = final_qrels['query'].replace('nan', np.nan)\n",
    "final_qrels_cleaned = final_qrels.dropna(subset=[\"query\"])\n",
    "final_qrels_cleaned = final_qrels_cleaned[final_qrels_cleaned[\"docid_index\"] != -1]\n",
    "\n",
    "# Reset index before further processing\n",
    "final_qrels_cleaned = final_qrels_cleaned.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff43106-20c0-45f7-a5e8-e95d0b801eec",
   "metadata": {},
   "source": [
    "# Part 2: Term Frequency Calculation for Documents\n",
    "\n",
    "- This part of the code computes the term frequency for each term in every document listed in the `final_qrels_cleaned` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79d4d279-d516-4668-bd37-4fc783c819c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute term frequencies for a given document\n",
    "def total_terms_doc_berechnen(docid):\n",
    "    total_terms_doc = 0  # Total number of terms in the document\n",
    "\n",
    "    # Sum up all term frequencies in the document\n",
    "    for posting in di.getPostings(doi.getDocumentEntry(docid)):\n",
    "        total_terms_doc += posting.getFrequency()\n",
    "\n",
    "    if total_terms_doc == 0:\n",
    "        return {}  # Return empty dict if no terms found\n",
    "\n",
    "    # Calculate normalized TF for each term\n",
    "    term_tf = {}\n",
    "    for posting in di.getPostings(doi.getDocumentEntry(docid)):\n",
    "        termid = posting.getId()\n",
    "        lex_entry = lex.getLexiconEntry(termid)\n",
    "        term = lex_entry.getKey()\n",
    "        freq = posting.getFrequency()\n",
    "        tf = freq / total_terms_doc\n",
    "        term_tf[term] = tf\n",
    "\n",
    "    return term_tf\n",
    "\n",
    "# Get only the column containing document index IDs\n",
    "docid_column = final_qrels_cleaned[[\"docid_index\"]]\n",
    "\n",
    "# Dictionary to store TF results for each document\n",
    "tf_results = {}\n",
    "\n",
    "# Compute term frequencies for each document\n",
    "for docid in docid_column[\"docid_index\"]:\n",
    "    tf_results[docid] = total_terms_doc_berechnen(docid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9bd830-4dad-4169-8d96-bea52f5ce4af",
   "metadata": {},
   "source": [
    "# Extracting Unique Terms\n",
    "\n",
    "- This code computes term frequencies (TF) for all terms in a document collection and extracts a list of unique terms found across all documents.\n",
    "- Terms are then filtered to remove stopwords, short words, and non-alphabetic tokens.\n",
    "- This is a preparation step for future document frequency (DF) computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3302b88d-9370-4f6c-b4ee-dd5d529fe81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('stopwords')  # Uncomment if running for the first time\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Load stopwords for both French and English\n",
    "french_stops = stopwords.words('french')\n",
    "engl_stops = stopwords.words('english')\n",
    "\n",
    "# Function to extract unique terms from a list of documents (no TF computation)\n",
    "def tf_werte_unique(dataframe):\n",
    "    tf_results_unique = {}  # Speichert TF-Werte für jedes Dokument\n",
    "\n",
    "    # Calculation of TF(t,d) for each document\n",
    "    for docid in final_qrels_cleaned[\"docid_index\"]:\n",
    "        total_terms_doc = 0\n",
    "        term_tf = {}\n",
    "\n",
    "        # Calculate the number of terms in the document\n",
    "        for posting in di.getPostings(doi.getDocumentEntry(docid)):\n",
    "            total_terms_doc += posting.getFrequency()\n",
    "\n",
    "        if total_terms_doc > 0:\n",
    "            for posting in di.getPostings(doi.getDocumentEntry(docid)):\n",
    "                termid = posting.getId()\n",
    "                lee = lex.getLexiconEntry(termid)\n",
    "                frequency_term_in_doc = posting.getFrequency()\n",
    "                tf = frequency_term_in_doc / total_terms_doc\n",
    "                term_tf[lee.getKey()] = tf  # Saving the TF values for the terms in the document\n",
    "\n",
    "        tf_results_unique.update(term_tf)\n",
    "\n",
    "    return tf_results_unique \n",
    "\n",
    "# Call to extract all unique terms from the documents in final_qrels_cleaned\n",
    "tf_results_unique = tf_werte_unique(final_qrels_cleaned)\n",
    "\n",
    "def extract(tf_results_unique):\n",
    "    unique_terms = list(tf_results_unique.keys())\n",
    "    return unique_terms \n",
    "\n",
    "unique = extract(tf_results_unique)\n",
    "\n",
    "# Apply filtering: keep only long, alphabetic, non-stopword terms\n",
    "unique_filtered = [\n",
    "    term for term in unique \n",
    "    if term.isalpha()\n",
    "    and len(term) >= 5\n",
    "    and term.lower() not in french_stops\n",
    "    and term.lower() not in engl_stops\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f72d74-2e23-4db2-8930-e54abe2a8797",
   "metadata": {},
   "source": [
    "# Part 3: Document Frequency Calculation for Terms\n",
    "\n",
    "- This function computes the document frequency (DF) for a set of prefiltered unique terms.\n",
    "- The function uses the inverted index to iterate over the postings list for each term and collects unique document IDs.\n",
    "- It returns a dictionary mapping terms to their DF values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "457a6330-2d12-473c-8c7d-1b0c73252434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_df_values(unique_terms_filtered):\n",
    "    df_results = {}\n",
    "\n",
    "    for term in unique_terms_filtered:\n",
    "        try:\n",
    "            # Get lexicon entry for the term\n",
    "            lex_entry = lex.getLexiconEntry(term)\n",
    "            if lex_entry is None:\n",
    "                print(f\"No lexicon entry for '{term}'. Skipping...\")\n",
    "                continue\n",
    "\n",
    "            # Use a set to ensure each document is only counted once\n",
    "            doc_ids = set()\n",
    "            for posting in inv.getPostings(lex_entry):\n",
    "                docno = meta.getItem(\"docno\", posting.getId())\n",
    "                doc_ids.add(docno)\n",
    "\n",
    "            df_results[term] = len(doc_ids)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing term '{term}': {e}\")\n",
    "            continue\n",
    "\n",
    "    return df_results\n",
    "\n",
    "# Execute DF calculation\n",
    "df_results = calculate_df_values(unique_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecf12c8-9f3c-4a33-acc6-39439cd6c596",
   "metadata": {},
   "source": [
    "# Part 4: IDF Calculation\n",
    "\n",
    "- This code computes the inverse document frequency (IDF) for a set of terms, based on the number of documents in which each term appears (DF). \n",
    "- The calculation uses a logarithmic formula with base 10 and applies smoothing to avoid division by zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e18fc34-80c7-4b79-8258-594d01513a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Total number of documents in the collection\n",
    "N = 2046080\n",
    "\n",
    "# Compute IDF values for each term\n",
    "idf_results = {}\n",
    "\n",
    "for term, df_value in df_results.items():\n",
    "    # Use smoothing (+1) to avoid division by zero\n",
    "    idf = math.log(N / (1 + df_value), 10)\n",
    "    idf_results[term] = idf  # Store the result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304ef508-c924-4e21-a7e2-0c2618e7b6c9",
   "metadata": {},
   "source": [
    "# Part 5: TF*IDF Calculation\n",
    "\n",
    "- This code calculates TF-IDF scores for each term in each document.\n",
    "- It is computed by multiplying the term frequency (TF) by the inverse document frequency (IDF) of that term.\n",
    "- The output is a nested dictionary structured as {doc_id: {term: tf-idf}}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26246cd2-fc14-41f6-bb7c-72b1743323b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tf_idf(tf_results, idf_results):\n",
    "    tf_idf_results = {}\n",
    "\n",
    "    for docid, terms in tf_results.items():\n",
    "        tf_idf_results[docid] = {}\n",
    "\n",
    "        for term, tf in terms.items():\n",
    "            if term in idf_results:\n",
    "                idf = idf_results[term]\n",
    "                tf_idf_results[docid][term] = tf * idf\n",
    "\n",
    "    return tf_idf_results\n",
    "\n",
    "# Compute TF-IDF values for all documents\n",
    "tf_idf_results = compute_tf_idf(tf_results, idf_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268b9e14-e73f-4a65-bb3f-feb1aae30b7f",
   "metadata": {},
   "source": [
    "# Part 6: Determine top 1 term per document\n",
    "\n",
    "- This function extracts the top-1 most important term per document based on the previously calculated TF-IDF scores.\n",
    "- For each document, it selects the term with the highest TF-IDF value and stores it as the representative or most significant term.\n",
    "- The result is a dictionary mapping each document ID to its highest-scoring (term, tf-idf) pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dab66534-0513-4ebc-ac85-c3959fa36d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_term_per_document(tf_idf_results):\n",
    "    top_terms = {}\n",
    "\n",
    "    for docid, terms in tf_idf_results.items():\n",
    "        if terms:\n",
    "            # Select the term with the highest TF-IDF score\n",
    "            top_term = max(terms.items(), key=lambda x: x[1])\n",
    "            top_terms[docid] = top_term\n",
    "\n",
    "    return top_terms\n",
    "\n",
    "# Get the top-1 term for each document\n",
    "top_terms_results = find_top_term_per_document(tf_idf_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4453e26-81ed-4651-a9dc-912bbb53e2e9",
   "metadata": {},
   "source": [
    "# Part 7: Create .csv file for each period\n",
    "\n",
    "- This part of the pipeline creates a .csv file that stores the top TF-IDF term for each query ID (qid).\n",
    "- For each qid, it collects top terms from the relevant documents, selects the highest-scoring term, and combines it with the original query for export.\n",
    "- The goal is to create an interpretable mapping from query to its most significant expansion term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d820172-35d1-4eca-8678-47d118cc0682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to hold rows for final CSV output\n",
    "csv_rows = []\n",
    "\n",
    "# Group by query ID (qid)\n",
    "for qid, group in final_qrels_cleaned.groupby('qid'):\n",
    "    terms_with_scores = []\n",
    "\n",
    "    # Collect top terms for documents linked to this query\n",
    "    for _, row in group.iterrows():\n",
    "        docid = row['docid_index']\n",
    "        if docid in top_terms_results:\n",
    "            top_term, tfidf_score = top_terms_results[docid]\n",
    "            terms_with_scores.append((top_term, tfidf_score))\n",
    "\n",
    "    # Remove duplicates, keep highest TF-IDF per term\n",
    "    term_score_dict = {}\n",
    "    for term, score in terms_with_scores:\n",
    "        if (term not in term_score_dict) or (score > term_score_dict[term]):\n",
    "            term_score_dict[term] = score\n",
    "\n",
    "    # Sort terms by TF-IDF in descending order\n",
    "    sorted_terms = sorted(term_score_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Select top-1 term for the query\n",
    "    if sorted_terms:\n",
    "        top_term, top_score = sorted_terms[0]\n",
    "    else:\n",
    "        top_term, top_score = \"\", 0.0\n",
    "\n",
    "    # Extract original query text (if any)\n",
    "    original_query = group['query'].iloc[0]\n",
    "    if not isinstance(original_query, str):\n",
    "        original_query = \"\"\n",
    "\n",
    "    # Append row for CSV\n",
    "    csv_rows.append({\n",
    "        \"qid\": qid,\n",
    "        \"query\": original_query,\n",
    "        \"z_9_term\": top_term,\n",
    "        \"z_9_tf_idf\": top_score\n",
    "    })\n",
    "\n",
    "# Create DataFrame from collected rows\n",
    "df_expanded = pd.DataFrame(csv_rows)\n",
    "\n",
    "# Write to CSV file\n",
    "df_expanded.to_csv(\"top_term.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749081aa-fc0f-49eb-97c2-6fbc02faa399",
   "metadata": {},
   "source": [
    "# Part 8: Merging Top Terms Across Time Periods\n",
    "\n",
    "- This part of the code merges multiple CSV files, each representing top TF-IDF terms per document for a specific time period.\n",
    "- The final output is a unified table where each row represents a query, and for each period, the top-scoring term is included.\n",
    "- This is useful for tracking how term importance evolves over time for recurring queries.\n",
    "- This part of the code should be run after ․csv files have been created for each time period․"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d585038-fa67-4538-a087-a0dae78829db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from functools import reduce\n",
    "import pandas as pd\n",
    "\n",
    "# Load all CSV files from the specified folder, sorted by filename\n",
    "dateien = sorted(glob.glob(\"top_term/*.csv\"))\n",
    "alle_dfs = []\n",
    "\n",
    "# Iterate over each CSV file\n",
    "for idx, datei in enumerate(dateien):\n",
    "    df = pd.read_csv(datei)\n",
    "\n",
    "    # Identify the relevant columns for term and tf-idf score\n",
    "    term_col = next((col for col in df.columns if col.startswith(\"z_\") and col.endswith(\"_term\")), None)\n",
    "    tfidf_col = next((col for col in df.columns if col.startswith(\"z_\") and col.endswith(\"_tf_idf\")), None)\n",
    "\n",
    "    # Skip files that do not contain both required columns\n",
    "    if not all([term_col, tfidf_col]):\n",
    "        continue\n",
    "\n",
    "    # Temporarily rename 'qid' to a unique identifier per file\n",
    "    df = df.rename(columns={\"qid\": f\"qid_{idx}\"})\n",
    "    df = df[[f\"qid_{idx}\", \"query\", term_col, tfidf_col]]  # Keep only necessary columns\n",
    "    alle_dfs.append(df)\n",
    "\n",
    "# Perform an outer join on the \"query\" column to merge all periods\n",
    "merged_df = reduce(lambda left, right: pd.merge(left, right, on=\"query\", how=\"outer\"), alle_dfs)\n",
    "\n",
    "# Create a unified 'qid' column by taking the first non-null qid across the merged columns\n",
    "qid_cols = [col for col in merged_df.columns if col.startswith(\"qid_\")]\n",
    "merged_df[\"qid\"] = merged_df[qid_cols].bfill(axis=1).iloc[:, 0]  # Use backfill to propagate the first available qid\n",
    "\n",
    "# Convert 'qid' to integer format while preserving NaN values\n",
    "merged_df[\"qid\"] = merged_df[\"qid\"].astype(\"Int64\")\n",
    "\n",
    "# Drop the temporary qid_* columns used during merging\n",
    "merged_df = merged_df.drop(columns=qid_cols)\n",
    "\n",
    "# Reorder columns: qid, query, then all other columns\n",
    "cols = [\"qid\", \"query\"] + [col for col in merged_df.columns if col not in [\"qid\", \"query\"]]\n",
    "merged_df = merged_df[cols]\n",
    "\n",
    "# Sort the final DataFrame by qid\n",
    "merged_df = merged_df.sort_values(by=\"qid\", ascending=True)\n",
    "\n",
    "# Save the resulting merged DataFrame to a CSV file\n",
    "merged_df.to_csv(\"mapping_9z.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c99a01-9ceb-4e57-b90e-49abb7f38075",
   "metadata": {},
   "source": [
    "# Part 9: Cleaning the Mapping Table\n",
    "\n",
    "- The first part eliminates any completely identical rows that may have resulted from merging multiple CSVs.\n",
    "- Since some queries (`qid`, `query`) may appear multiple times with different TF-IDF scores across time periods, the code calculates the average TF-IDF score per row and keeps only the highest-scoring row per `(qid, query)` pair.\n",
    "- The cleaned and deduplicated mapping table is saved to new .csv file, sorted by `qid`.\n",
    "- This step ensures data integrity and prepares the table for further analysis or visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d632e687-6a49-41c8-89f2-d7242b4db406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the mapping file\n",
    "df = pd.read_csv(\"mapping_9z.csv\")\n",
    "\n",
    "# Remove exact duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Identify TF-IDF columns\n",
    "tfidf_cols = [col for col in df.columns if \"tf_idf\" in col]\n",
    "\n",
    "# Compute average TF-IDF score across time periods\n",
    "df[\"tfidf_avg\"] = df[tfidf_cols].mean(axis=1)\n",
    "\n",
    "# Keep only the highest scoring row per (qid, query) pair\n",
    "df = df.sort_values(\"tfidf_avg\", ascending=False).drop_duplicates(subset=[\"qid\", \"query\"])\n",
    "\n",
    "# Drop the helper column\n",
    "df = df.drop(columns=\"tfidf_avg\")\n",
    "\n",
    "# Sort the final DataFrame by qid\n",
    "df = df.sort_values(by=\"qid\", ascending=True)\n",
    "\n",
    "# Save the cleaned and deduplicated file\n",
    "df.to_csv(\"mapping_9z_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e7f465-ad3a-4c00-9b5b-36211135133c",
   "metadata": {},
   "source": [
    "# Part 10: Query Expansion with Top Terms\n",
    "\n",
    "- This step enriches each original query with its most relevant terms based on TF-IDF scores across 9 distinct time periods.\n",
    "- Each query is mapped to its top TF-IDF terms (`z_1` to `z_9`) from 9 temporal snapshots.\n",
    "- Terms are deduplicated per `qid` by keeping only the instance with the highest TF-IDF score. Then they are sorted and the top 9 are retained.\n",
    "- For each query, its top terms are appended to the original query text. If no top terms exist, the query remains unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f28d33-e69e-4032-9907-4fc12268a16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the original queries file (qid and query text)\n",
    "queries_df = pd.read_csv(\n",
    "    \"datasets/LongEval-Web/LongEval Test Collection/queries/2023-08_queries.txt\",\n",
    "    sep=\"\\t\", names=[\"qid\", \"query\"], dtype={\"qid\": str}\n",
    ")\n",
    "\n",
    "# Load the cleaned TF-IDF file with top terms from 9 time periods\n",
    "tfidf_df = pd.read_csv(\"top_term/mapping_9z_cleaned.csv\", dtype={\"qid\": str})\n",
    "\n",
    "# Dictionary to store the top N unique terms per qid\n",
    "qid_best_terms = {}\n",
    "\n",
    "# Iterate over each row in the TF-IDF mapping\n",
    "for _, row in tfidf_df.iterrows():\n",
    "    qid = row['qid']\n",
    "    term_scores = []\n",
    "\n",
    "    # Collect all (term, score) pairs from z_1 to z_9\n",
    "    for i in range(1, 10):\n",
    "        term_col = f\"z_{i}_term\"\n",
    "        score_col = f\"z_{i}_tf_idf\"\n",
    "\n",
    "        term = row.get(term_col)\n",
    "        score = row.get(score_col)\n",
    "\n",
    "        if isinstance(term, str) and pd.notna(score):\n",
    "            term_scores.append((term, score))\n",
    "\n",
    "    # Deduplicate terms by keeping only the one with the highest score\n",
    "    term_dict = {}\n",
    "    for term, score in term_scores:\n",
    "        if term not in term_dict or score > term_dict[term]:\n",
    "            term_dict[term] = score\n",
    "\n",
    "    # Sort terms by TF-IDF score (descending)\n",
    "    unique_term_scores = sorted(term_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Select the top 9 terms\n",
    "    best_terms = [term for term, _ in unique_term_scores[:9]]\n",
    "\n",
    "    # Save top terms for this query id\n",
    "    if best_terms:\n",
    "        qid_best_terms[qid] = best_terms\n",
    "\n",
    "# Create new rows with expanded queries\n",
    "expanded_rows = []\n",
    "\n",
    "for _, row in queries_df.iterrows():\n",
    "    qid = row['qid']\n",
    "    query = row['query']\n",
    "\n",
    "    # If expansion terms exist, append them to the original query\n",
    "    if qid in qid_best_terms:\n",
    "        expanded_query = query + \" \" + \" \".join(qid_best_terms[qid])\n",
    "    else:\n",
    "        expanded_query = query  # No expansion available\n",
    "\n",
    "    expanded_rows.append({\"qid\": qid, \"query\": expanded_query})\n",
    "\n",
    "# Save the expanded queries to a .txt file; d = distinct; 9z = 9 Zeiträume; 9t = 9 Terme\n",
    "with open(\"expanded_queries_23-08_d_9z_9t.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for row in expanded_rows:\n",
    "        f.write(f\"{row['qid']}\\t{row['query']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e956e3b-1919-4b99-98b6-25e731d2d70e",
   "metadata": {},
   "source": [
    "# Part 11: Retrieval and Evaluation using BM25 \n",
    "\n",
    "- This final step assesses how effective the query expansion (via temporal top terms) was in improving retrieval performance on a standard test collection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71aaf13-b5b8-43d3-bfc2-30316168a8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pyterrier as pt\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the PyTerrier Java virtual machine if it's not already running\n",
    "if not pt.java.started():\n",
    "    pt.java.init()\n",
    "\n",
    "# Define index path and load the index\n",
    "index_path = os.path.abspath(\"datasets/LongEval-Web/index/longeval-web-fr-2023-08-pyterrier\")\n",
    "index = pt.IndexFactory.of(index_path)\n",
    "\n",
    "# Load configuration from YAML\n",
    "BASE_PATH = \"datasets/LongEval-Web\"\n",
    "with open(BASE_PATH + \"/metadata.yml\", \"r\") as yamlfile:\n",
    "    config = yaml.load(yamlfile, Loader=yaml.FullLoader)\n",
    "\n",
    "# Dataset identifiers\n",
    "dataset = \"longeval-web\"\n",
    "language = \"fr\"\n",
    "sub_collection = \"2023-08\"\n",
    "\n",
    "# Load expanded queries from the specified file\n",
    "topics_path = os.path.join(\"expended_queries/expanded_queries_23-08_d_9z_9t.txt\")\n",
    "topics = pd.read_csv(topics_path, sep=\"\\t\", names=[\"qid\", \"query\"])\n",
    "topics[\"qid\"] = topics[\"qid\"].astype(str)\n",
    "\n",
    "# Clean queries by removing problematic characters\n",
    "topics[\"query\"] = topics[\"query\"].str.replace(\"'\", \"\")\n",
    "topics[\"query\"] = topics[\"query\"].str.replace(\"*\", \"\")\n",
    "topics[\"query\"] = topics[\"query\"].str.replace(\"/\", \"\")\n",
    "topics[\"query\"] = topics[\"query\"].str.replace(\":\", \"\")\n",
    "topics[\"query\"] = topics[\"query\"].str.replace(\"?\", \"\")\n",
    "topics[\"query\"] = topics[\"query\"].str.replace(\")\", \"\")\n",
    "topics[\"query\"] = topics[\"query\"].str.replace(\"(\", \"\")\n",
    "topics[\"query\"] = topics[\"query\"].str.replace(\"+\", \"\")\n",
    "\n",
    "# Remove known spam queries by qid\n",
    "spam = [\"59769\", \"6060\", \"75200\", \"74351\", \"67599\", \"74238\", \"74207\", \"75100\", \"58130\"]\n",
    "topics = topics[~topics[\"qid\"].isin(spam)]\n",
    "\n",
    "# Instantiate BM25 retriever\n",
    "BM25 = pt.terrier.Retriever(index, wmodel=\"BM25\", verbose=True)\n",
    "\n",
    "# Apply BM25 to get ranking results for the topics\n",
    "run = BM25.transform(topics)\n",
    "\n",
    "# Save the run file in TREC format (.gz compressed)\n",
    "pt.io.write_results(\n",
    "    run,\n",
    "    f\"{dataset}-{language}-{sub_collection}-BM25-expanded.gz\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
